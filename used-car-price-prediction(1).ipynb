{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nfrom category_encoders import OneHotEncoder # transformer for non numeric value\nimport seaborn as sns\nfrom sklearn.linear_model import Ridge # Train model\nfrom sklearn.pipeline import make_pipeline # Pipeline\nfrom sklearn.impute import SimpleImputer  # Impute missing values\nfrom sklearn.metrics import mean_absolute_error # Evaluate model\nfrom sklearn.utils.validation import check_is_fitted # check for if data fitted to model\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-04T17:56:11.644693Z","iopub.execute_input":"2022-05-04T17:56:11.645079Z","iopub.status.idle":"2022-05-04T17:56:13.310785Z","shell.execute_reply.started":"2022-05-04T17:56:11.644981Z","shell.execute_reply":"2022-05-04T17:56:13.309908Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"ford.csv\")\nprint(df.shape)\ndf.info()\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T17:56:13.312562Z","iopub.execute_input":"2022-05-04T17:56:13.312788Z","iopub.status.idle":"2022-05-04T17:56:13.414572Z","shell.execute_reply.started":"2022-05-04T17:56:13.312762Z","shell.execute_reply":"2022-05-04T17:56:13.413959Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate\n","metadata":{}},{"cell_type":"code","source":"# One of our main feature is mileage\ndf[\"mileage\"].describe()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T17:56:13.415759Z","iopub.execute_input":"2022-05-04T17:56:13.416225Z","iopub.status.idle":"2022-05-04T17:56:13.428740Z","shell.execute_reply.started":"2022-05-04T17:56:13.416193Z","shell.execute_reply":"2022-05-04T17:56:13.427385Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"There is big difference in mean and median value of mileage, and min mileage are even 1 and maximum mileage are in even 5 digits,  \nfor good prediction we have to remove this extreme values from either ends by removing outliers","metadata":{}},{"cell_type":"code","source":"# Remove outliers from the numeric data\n# mileage\n\nplt.hist(df[\"mileage\"])\nplt.xlabel(\"Mileage\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Histogram: Mileage\");","metadata":{"execution":{"iopub.status.busy":"2022-05-04T17:56:13.431395Z","iopub.execute_input":"2022-05-04T17:56:13.431951Z","iopub.status.idle":"2022-05-04T17:56:13.646868Z","shell.execute_reply.started":"2022-05-04T17:56:13.431903Z","shell.execute_reply":"2022-05-04T17:56:13.646044Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Data is more skewed toward the left","metadata":{}},{"cell_type":"code","source":"plt.boxplot(df[\"mileage\"], vert=False)\nplt.xlabel(\"Mileage\")\nplt.title(\"Boxplot: Mileage\");","metadata":{"execution":{"iopub.status.busy":"2022-05-04T17:56:13.648220Z","iopub.execute_input":"2022-05-04T17:56:13.648727Z","iopub.status.idle":"2022-05-04T17:56:13.831126Z","shell.execute_reply.started":"2022-05-04T17:56:13.648684Z","shell.execute_reply":"2022-05-04T17:56:13.830556Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"after looking at boxplot we can say that their are outliers","metadata":{}},{"cell_type":"code","source":"low, high = df[\"mileage\"].quantile([0.05,0.90])\nmask_ma = df[\"mileage\"].between(low,high)\ndf = df[mask_ma]","metadata":{"execution":{"iopub.status.busy":"2022-05-04T17:56:13.832007Z","iopub.execute_input":"2022-05-04T17:56:13.832591Z","iopub.status.idle":"2022-05-04T17:56:13.843996Z","shell.execute_reply.started":"2022-05-04T17:56:13.832558Z","shell.execute_reply":"2022-05-04T17:56:13.843287Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"plt.boxplot(df[\"mileage\"], vert=False)\nplt.xlabel(\"Mileage\")\nplt.title(\"Boxplot: Mileage\");","metadata":{"execution":{"iopub.status.busy":"2022-05-04T17:56:13.845202Z","iopub.execute_input":"2022-05-04T17:56:13.845405Z","iopub.status.idle":"2022-05-04T17:56:14.020683Z","shell.execute_reply.started":"2022-05-04T17:56:13.845380Z","shell.execute_reply":"2022-05-04T17:56:14.019866Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Drop values with more than half missing values\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T17:56:14.021899Z","iopub.execute_input":"2022-05-04T17:56:14.022228Z","iopub.status.idle":"2022-05-04T17:56:14.037311Z","shell.execute_reply.started":"2022-05-04T17:56:14.022183Z","shell.execute_reply":"2022-05-04T17:56:14.036365Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"There is no null value","metadata":{}},{"cell_type":"code","source":"# Drop columns with low- and high- cardinalty from categorical data\n# Year of production is also categorical function\ndf[\"year\"] = df[\"year\"].astype(\"object\")\ndf.select_dtypes(\"object\").nunique()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-04T17:56:14.039185Z","iopub.execute_input":"2022-05-04T17:56:14.039751Z","iopub.status.idle":"2022-05-04T17:56:14.059795Z","shell.execute_reply.started":"2022-05-04T17:56:14.039707Z","shell.execute_reply":"2022-05-04T17:56:14.059004Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df.drop(columns=[\"transmission\",\"fuelType\"],inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T17:56:14.062102Z","iopub.execute_input":"2022-05-04T17:56:14.062313Z","iopub.status.idle":"2022-05-04T17:56:14.068274Z","shell.execute_reply.started":"2022-05-04T17:56:14.062287Z","shell.execute_reply":"2022-05-04T17:56:14.067545Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Drop columns with multi-colinearity\ncorr = df.select_dtypes(\"number\").drop(columns=\"price\").corr()  # droping price column 'coz its our target \ncorr","metadata":{"execution":{"iopub.status.busy":"2022-05-04T17:56:14.069345Z","iopub.execute_input":"2022-05-04T17:56:14.069570Z","iopub.status.idle":"2022-05-04T17:56:14.094561Z","shell.execute_reply.started":"2022-05-04T17:56:14.069542Z","shell.execute_reply":"2022-05-04T17:56:14.093676Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"We can get the idea of which columns has multi-colinearity after looking at table above, but it is always easy and effective to do this by visualisation.","metadata":{"execution":{"iopub.status.busy":"2022-04-26T13:59:18.760309Z","iopub.execute_input":"2022-04-26T13:59:18.760639Z","iopub.status.idle":"2022-04-26T13:59:18.766806Z","shell.execute_reply.started":"2022-04-26T13:59:18.760609Z","shell.execute_reply":"2022-04-26T13:59:18.765819Z"}}},{"cell_type":"code","source":"# Heatmap\nsns.heatmap(corr);","metadata":{"execution":{"iopub.status.busy":"2022-05-04T17:56:14.095673Z","iopub.execute_input":"2022-05-04T17:56:14.095891Z","iopub.status.idle":"2022-05-04T17:56:14.346904Z","shell.execute_reply.started":"2022-05-04T17:56:14.095867Z","shell.execute_reply":"2022-05-04T17:56:14.346331Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"after looking this visualisation or above \"corr\" table we can say that their is no multicolinearity in our feature columns,","metadata":{}},{"cell_type":"markdown","source":"Done! It looks like we're going to use our six features to predict the price","metadata":{"execution":{"iopub.status.busy":"2022-04-26T14:01:07.144892Z","iopub.execute_input":"2022-04-26T14:01:07.146096Z","iopub.status.idle":"2022-04-26T14:01:07.163014Z","shell.execute_reply.started":"2022-04-26T14:01:07.146036Z","shell.execute_reply":"2022-04-26T14:01:07.161986Z"}}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T17:56:14.347797Z","iopub.execute_input":"2022-05-04T17:56:14.348206Z","iopub.status.idle":"2022-05-04T17:56:14.360437Z","shell.execute_reply.started":"2022-05-04T17:56:14.348169Z","shell.execute_reply":"2022-05-04T17:56:14.359847Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Split Data","metadata":{}},{"cell_type":"code","source":"feature = [\"model\",\"year\",\"mileage\",\"mpg\",\"engineSize\"]\ntarget = \"price\"\n\nX = df[feature]\ny = df[target]\n# split data into training and testing set\nX_train,X_test,y_train,y_test = train_test_split(X,y,shuffle=True, train_size=0.8)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T17:56:14.361416Z","iopub.execute_input":"2022-05-04T17:56:14.362115Z","iopub.status.idle":"2022-05-04T17:56:14.376850Z","shell.execute_reply.started":"2022-05-04T17:56:14.362080Z","shell.execute_reply":"2022-05-04T17:56:14.376240Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Build Model","metadata":{}},{"cell_type":"markdown","source":"## Baseline Model","metadata":{}},{"cell_type":"code","source":"y_mean = y_train.mean()\ny_pred_baseline = [y_mean] * len(y_train)\n\nprint(\"Mean car price:\", y_mean.round(2))\nprint(\"Mean Absolute Error for Baseline Model:\",mean_absolute_error(y_train,y_pred_baseline).round(2))","metadata":{"execution":{"iopub.status.busy":"2022-05-04T17:56:14.378048Z","iopub.execute_input":"2022-05-04T17:56:14.378537Z","iopub.status.idle":"2022-05-04T17:56:14.388720Z","shell.execute_reply.started":"2022-05-04T17:56:14.378508Z","shell.execute_reply":"2022-05-04T17:56:14.387818Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"Our trained model should perform better than this so we can say that our model's performance is good","metadata":{}},{"cell_type":"markdown","source":"## Iterate","metadata":{}},{"cell_type":"code","source":"# Pipeline\nmodel = make_pipeline(\n    OneHotEncoder(use_cat_names=True), # Encoding non numerical values\n    SimpleImputer(),# Imput missing values\n    Ridge() # Predictor of linear_model (part of linear regression)\n)\n\n# Fit\nmodel.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T17:56:14.389835Z","iopub.execute_input":"2022-05-04T17:56:14.390087Z","iopub.status.idle":"2022-05-04T17:56:14.549369Z","shell.execute_reply.started":"2022-05-04T17:56:14.390059Z","shell.execute_reply":"2022-05-04T17:56:14.548244Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Check\ncheck_is_fitted(model[\"ridge\"])","metadata":{"execution":{"iopub.status.busy":"2022-05-04T17:56:14.550856Z","iopub.execute_input":"2022-05-04T17:56:14.551186Z","iopub.status.idle":"2022-05-04T17:56:14.556087Z","shell.execute_reply.started":"2022-05-04T17:56:14.551145Z","shell.execute_reply":"2022-05-04T17:56:14.555040Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Predict for training data\ny_pred_train = model.predict(X_train)\ny_pred_train = pd.Series(y_pred_train)  # Convert array of predicted value into Series","metadata":{"execution":{"iopub.status.busy":"2022-05-04T17:56:14.557727Z","iopub.execute_input":"2022-05-04T17:56:14.558092Z","iopub.status.idle":"2022-05-04T17:56:14.645891Z","shell.execute_reply.started":"2022-05-04T17:56:14.558005Z","shell.execute_reply":"2022-05-04T17:56:14.644792Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Evaluate\nprint(\"Mean Absolute Error for training model:\", mean_absolute_error(y_train,y_pred_train).round(2))","metadata":{"execution":{"iopub.status.busy":"2022-05-04T17:56:14.647437Z","iopub.execute_input":"2022-05-04T17:56:14.648289Z","iopub.status.idle":"2022-05-04T17:56:14.655698Z","shell.execute_reply.started":"2022-05-04T17:56:14.648237Z","shell.execute_reply":"2022-05-04T17:56:14.654694Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"Mean Absolute Error for training model is very much less than that of baseline model, that mean our model's performance is good","metadata":{}},{"cell_type":"markdown","source":"# Test Model","metadata":{}},{"cell_type":"markdown","source":"Let's have a look at testing model, see if it generalize on test data","metadata":{}},{"cell_type":"code","source":"# Predict\ny_pred_test = pd.Series(model.predict(X_test))\n# Evaluate\nprint(\"Mean Absolute Error for Test Model:\", mean_absolute_error(y_test,y_pred_test).round(2))","metadata":{"execution":{"iopub.status.busy":"2022-05-04T17:56:14.657628Z","iopub.execute_input":"2022-05-04T17:56:14.658244Z","iopub.status.idle":"2022-05-04T17:56:14.694836Z","shell.execute_reply.started":"2022-05-04T17:56:14.658196Z","shell.execute_reply":"2022-05-04T17:56:14.693961Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"Mean Absolute Error for Test Model is very lower than that of baseline model and very similar of training model.","metadata":{}}]}